# robots.txt
User-agent: Googlebot
Disallow: 
User-agent: 360Spider
Disallow: 
User-agent: googlebot-image
Disallow: 
User-agent: baiduspider
Disallow: 
User-agent: *
Disallow: 
Crawl-delay: 20
Disallow: /cgi-bin/